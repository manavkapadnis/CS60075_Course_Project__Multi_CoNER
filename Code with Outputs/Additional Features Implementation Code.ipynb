{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import required libraries\n---","metadata":{}},{"cell_type":"code","source":"import os\nimport gzip\nimport ast\nimport itertools\nimport logging\nimport torch\nfrom typing import List, Any\nimport torch.nn.functional as F\nimport numpy as np\nimport pandas as pd\nfrom allennlp.modules import ConditionalRandomField\nfrom allennlp.modules.conditional_random_field import allowed_transitions\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom transformers import get_linear_schedule_with_warmup, AutoModel\nfrom torch.utils.data import Dataset\nfrom transformers import AutoTokenizer\nfrom collections import defaultdict\nfrom typing import Set\nfrom overrides import overrides\nfrom allennlp.training.metrics.metric import Metric\nimport argparse\nimport time\nfrom pytorch_lightning import seed_everything\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, EarlyStopping\nimport warnings\nfrom tqdm import tqdm\nimport random as rn\n\nfrom pandarallel import pandarallel\n# Initialization\npandarallel.initialize(progress_bar = True)\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:46:34.261807Z","iopub.execute_input":"2021-11-24T06:46:34.262191Z","iopub.status.idle":"2021-11-24T06:46:49.274804Z","shell.execute_reply.started":"2021-11-24T06:46:34.262094Z","shell.execute_reply":"2021-11-24T06:46:49.273678Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"INFO: Pandarallel will run on 2 workers.\nINFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n","output_type":"stream"}]},{"cell_type":"code","source":"conll_iob = {'B-ORG': 0, 'I-ORG': 1, 'B-MISC': 2, 'I-MISC': 3, 'B-LOC': 4, \n             'I-LOC': 5, 'B-PER': 6, 'I-PER': 7, 'O': 8}\nwnut_iob = {'B-CORP': 0, 'I-CORP': 1, 'B-CW': 2, 'I-CW': 3, 'B-GRP': 4, \n            'I-GRP': 5, 'B-LOC': 6, 'I-LOC': 7, 'B-PER': 8, 'I-PER': 9, \n            'B-PROD': 10, 'I-PROD': 11, 'O': 12}\nSEED = 42\nrn.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:46:49.277255Z","iopub.execute_input":"2021-11-24T06:46:49.277537Z","iopub.status.idle":"2021-11-24T06:46:49.295166Z","shell.execute_reply.started":"2021-11-24T06:46:49.277487Z","shell.execute_reply":"2021-11-24T06:46:49.294023Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Loading Functions and Class\n---","metadata":{}},{"cell_type":"code","source":"def get_ner_reader(data):\n    \n    # 'fields' contains 4 lists \n    # The first list is the list of words present in the sentence\n    # The last list is the list of ner tags of the words.\n    \n    fin = gzip.open(data, 'rt') if data.endswith('.gz') else open(data, 'rt')\n    \n    for is_divider, lines in itertools.groupby(fin, _is_divider):\n        \n        if is_divider:\n            continue\n        \n        fields = [line.strip().split() for line in lines]\n        fields = [list(field) for field in zip(*fields)]\n        \n        yield fields\n\n# Function to assign the new tags \ndef _assign_ner_tags(ner_tag, rep_):\n    \n    ner_tags_rep = []\n    token_masks = []\n\n    sub_token_len = len(rep_)\n    token_masks.extend([True] * sub_token_len)\n    \n    if ner_tag[0] == 'B':\n        \n        in_tag = 'I' + ner_tag[1:]\n        ner_tags_rep.append(ner_tag)\n        ner_tags_rep.extend([in_tag] * (sub_token_len - 1))\n    \n    else:\n        ner_tags_rep.extend([ner_tag] * sub_token_len)\n    \n    return ner_tags_rep, token_masks\n\n# Function to extract spans (BI spans) and store in a dictionary\ndef extract_spans(tags):\n    \n    cur_tag = None\n    cur_start = None\n    gold_spans = {}\n\n    def _save_span(_cur_tag, _cur_start, _cur_id, _gold_spans):\n        \n        if _cur_start is None:\n            return _gold_spans\n        \n        _gold_spans[(_cur_start, _cur_id - 1)] = _cur_tag  # inclusive start & end, accord with conll-coref settings\n        \n        return _gold_spans\n\n    # iterate over the tags\n    for _id, nt in enumerate(tags):\n        \n        indicator = nt[0]\n        \n        if indicator == 'B':\n            gold_spans = _save_span(cur_tag, cur_start, _id, gold_spans)\n            cur_start = _id\n            cur_tag = nt[2:]\n            pass\n        \n        elif indicator == 'I':\n            # do nothing\n            pass\n        \n        elif indicator == 'O':\n            gold_spans = _save_span(cur_tag, cur_start, _id, gold_spans)\n            cur_tag = 'O'\n            cur_start = _id\n            pass\n    \n    _save_span(cur_tag, cur_start, _id + 1, gold_spans)\n    \n    return gold_spans\n\n\ndef _is_divider(line: str) -> bool:\n    \n    empty_line = line.strip() == ''\n    \n    if empty_line:\n        return True\n\n    first_token = line.split()[0]\n    if first_token == \"-DOCSTART-\" or line.startswith('# id'):  # pylint: disable=simplifiable-if-statement\n        return True\n\n    return False","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:46:49.297755Z","iopub.execute_input":"2021-11-24T06:46:49.298639Z","iopub.status.idle":"2021-11-24T06:46:49.316828Z","shell.execute_reply.started":"2021-11-24T06:46:49.298562Z","shell.execute_reply":"2021-11-24T06:46:49.315327Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CoNLLReader(Dataset):\n    \n    def __init__(self, max_instances = -1, max_length = 50, target_vocab = None, \n                 pretrained_dir = '', encoder_model = 'xlm-roberta-large', feature_type = 'encoded_noun_features'):\n        \n        self.feature_type = feature_type\n        \n        self._max_instances = max_instances\n        self._max_length = max_length\n\n        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_dir + encoder_model)\n\n        self.pad_token = self.tokenizer.special_tokens_map['pad_token']\n        self.pad_token_id = self.tokenizer.get_vocab()['pad']\n        self.sep_token = self.tokenizer.special_tokens_map['sep_token']\n\n        self.label_to_id = {} if target_vocab is None else target_vocab\n        self.instances = []\n\n    def get_target_size(self):\n        return len(set(self.label_to_id.values()))\n\n    def get_target_vocab(self):\n        return self.label_to_id\n\n    def __len__(self):\n        return len(self.instances)\n\n    def __getitem__(self, item):\n        return self.instances[item]\n    \n    def give_list(self, sentence):\n        res = ast.literal_eval(sentence)\n        return res\n    \n    def get_encoded_features(self, features_data):\n        \n        df = pd.read_csv(features_data)\n        features_list = df[self.feature_type].parallel_apply(lambda x: self.give_list(x))\n        return features_list\n        \n    def read_data(self, data, features_data):\n        \n        dataset_name = data if isinstance(data, str) else 'dataframe'\n        print(\"Obtaining {} from {}\".format(self.feature_type, features_data))\n        features_list = self.get_encoded_features(features_data)\n        \n        print(\"Reading file {}\".format(dataset_name))\n        instance_idx = 0\n        \n        for fields, features in tqdm(zip(get_ner_reader(data = data), features_list)):\n            \n            if self._max_instances != -1 and instance_idx > self._max_instances:\n                break\n            \n            sentence_str, tokens_sub_rep, token_masks_rep, coded_ner_, gold_spans_ = self.parse_line_for_ner(fields = fields)\n            \n            tokens_tensor = torch.tensor(tokens_sub_rep, dtype = torch.long)\n            tag_tensor = torch.tensor(coded_ner_, dtype = torch.long).unsqueeze(0)\n            token_masks_rep = torch.tensor(token_masks_rep)\n            features_tensor = torch.tensor(features)\n            \n            self.instances.append((tokens_tensor, token_masks_rep, gold_spans_, tag_tensor, features_tensor))\n            instance_idx += 1\n                    \n        print(\"Finished reading {:d} instances from file {}\".format(len(self.instances), dataset_name))\n    \n    def parse_line_for_ner(self, fields):\n        \n        tokens_, ner_tags = fields[0], fields[-1]\n\n        sentence_str, tokens_sub_rep, ner_tags_rep, token_masks_rep = self.parse_tokens_for_ner(tokens_, ner_tags)\n        gold_spans_ = extract_spans(ner_tags_rep)\n        coded_ner_ = [self.label_to_id[tag] for tag in ner_tags_rep]\n\n        return sentence_str, tokens_sub_rep, token_masks_rep, coded_ner_, gold_spans_\n\n    def parse_tokens_for_ner(self, tokens_, ner_tags):\n        \n        sentence_str = ''\n        tokens_sub_rep, ner_tags_rep = [self.pad_token_id], ['O']\n        \n        for idx, token in enumerate(tokens_):\n            \n            if self._max_length != -1 and len(tokens_sub_rep) > self._max_length:\n                break\n            \n            sentence_str += ' ' + ' '.join(self.tokenizer.tokenize(token.lower()))\n            rep_ = self.tokenizer(token.lower())['input_ids']\n            rep_ = rep_[1:-1]\n            tokens_sub_rep.extend(rep_)\n\n            # if we have a NER here, in the case of B, the first NER tag is the B tag, the rest are I tags.\n            ner_tag = ner_tags[idx]\n            tags, masks = _assign_ner_tags(ner_tag, rep_)\n            ner_tags_rep.extend(tags)\n\n        tokens_sub_rep.append(self.pad_token_id)\n        ner_tags_rep.append('O')\n        token_masks_rep = [True] * len(tokens_sub_rep)\n        \n        return sentence_str, tokens_sub_rep, ner_tags_rep, token_masks_rep","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:46:49.319626Z","iopub.execute_input":"2021-11-24T06:46:49.320259Z","iopub.status.idle":"2021-11-24T06:46:49.346102Z","shell.execute_reply.started":"2021-11-24T06:46:49.320189Z","shell.execute_reply":"2021-11-24T06:46:49.345039Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_tagset(tagging_scheme):\n    if 'conll' in tagging_scheme:\n        return conll_iob\n    return wnut_iob\n\ndef get_reader(file_path, features_file_path, max_instances=-1, max_length=50, target_vocab=None, encoder_model='xlm-roberta-large', feature_type = 'encoded_noun_features'):\n    if file_path is None:\n        return None\n    reader = CoNLLReader(max_instances=max_instances, max_length=max_length, target_vocab=target_vocab, encoder_model=encoder_model, feature_type = feature_type)\n    reader.read_data(file_path, features_file_path)\n\n    return reader","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:46:49.349259Z","iopub.execute_input":"2021-11-24T06:46:49.350357Z","iopub.status.idle":"2021-11-24T06:46:49.362026Z","shell.execute_reply.started":"2021-11-24T06:46:49.350312Z","shell.execute_reply":"2021-11-24T06:46:49.360932Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Args Class\n---","metadata":{}},{"cell_type":"code","source":"class Args():\n    \n    def __init__(self):\n        \n        self.train = '../input/semeval-task-11/EN-English/en_train.conll'\n        self.test = '../input/semeval-task-11/EN-English/en_dev.conll'\n        self.dev = '../input/semeval-task-11/EN-English/en_dev.conll'\n        \n        self.train_features = '../input/semeval-task-11/en_train_features.csv'\n        self.test_features = '../input/semeval-task-11/en_dev_features.csv'\n        self.dev_features = '../input/semeval-task-11/en_dev_features.csv'\n        \n        # Feature type will be either 'encoded_noun_features' or 'encoded_dependency_features'\n        self.feature_type = 'encoded_dependency_features'\n        self.feature_length = 44\n        \n        self.out_dir = './'\n        self.iob_tagging = 'wnut'\n        \n        self.max_instances = -1\n        self.max_length = 50\n        \n        # encoder_model can be bert-base-multilingual-cased or xlm-roberta-base or ai4bharat/indic-bert \n        self.encoder_model = 'bert-base-multilingual-cased'\n        self.model = './'\n        self.model_name = 'bert-base-multilingual-cased'\n        self.stage = 'fit'\n        self.prefix = 'test'\n\n        self.batch_size = 32\n        self.gpus = 1\n        self.device = 'cuda'\n        self.epochs = 3\n        self.lr = 1e-5\n        self.dropout = 0.1\n        self.max_grad_norm = 1.0","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:47:13.700723Z","iopub.execute_input":"2021-11-24T06:47:13.701352Z","iopub.status.idle":"2021-11-24T06:47:13.711294Z","shell.execute_reply.started":"2021-11-24T06:47:13.701304Z","shell.execute_reply":"2021-11-24T06:47:13.710199Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sg = Args()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:47:14.687832Z","iopub.execute_input":"2021-11-24T06:47:14.688556Z","iopub.status.idle":"2021-11-24T06:47:14.694478Z","shell.execute_reply.started":"2021-11-24T06:47:14.688501Z","shell.execute_reply":"2021-11-24T06:47:14.692591Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Metric\n---","metadata":{}},{"cell_type":"code","source":"class SpanF1(Metric):\n    \n    def __init__(self, non_entity_labels = ['O']) -> None:\n        \n        self._num_gold_mentions = 0\n        self._num_recalled_mentions = 0\n        self._num_predicted_mentions = 0\n        self._TP, self._FP, self._GT = defaultdict(int), defaultdict(int), defaultdict(int)\n        self.non_entity_labels = set(non_entity_labels)\n\n    @overrides\n    def __call__(self, batched_predicted_spans, batched_gold_spans, sentences = None):\n        \n        non_entity_labels = self.non_entity_labels\n\n        for predicted_spans, gold_spans in zip(batched_predicted_spans, batched_gold_spans):\n            gold_spans_set = set([x for x, y in gold_spans.items() if y not in non_entity_labels])\n            pred_spans_set = set([x for x, y in predicted_spans.items() if y not in non_entity_labels])\n\n            self._num_gold_mentions += len(gold_spans_set)\n            self._num_recalled_mentions += len(gold_spans_set & pred_spans_set)\n            self._num_predicted_mentions += len(pred_spans_set)\n\n            for ky, val in gold_spans.items():\n                if val not in non_entity_labels:\n                    self._GT[val] += 1\n\n            for ky, val in predicted_spans.items():\n                if val in non_entity_labels:\n                    continue\n                if ky in gold_spans and val == gold_spans[ky]:\n                    self._TP[val] += 1\n                else:\n                    self._FP[val] += 1\n\n    @overrides\n    def get_metric(self, reset: bool = False) -> float:\n        \n        all_tags: Set[str] = set()\n        all_tags.update(self._TP.keys())\n        all_tags.update(self._FP.keys())\n        all_tags.update(self._GT.keys())\n        all_metrics = {}\n\n        for tag in all_tags:\n            precision, recall, f1_measure = self.compute_prf_metrics(true_positives=self._TP[tag],\n                                                                     false_negatives=self._GT[tag] - self._TP[tag],\n                                                                     false_positives=self._FP[tag])\n            all_metrics['P@{}'.format(tag)] = precision\n            all_metrics['R@{}'.format(tag)] = recall\n            all_metrics['F1@{}'.format(tag)] = f1_measure\n\n        # Compute the precision, recall and f1 for all spans jointly.\n        precision, recall, f1_measure = self.compute_prf_metrics(true_positives=sum(self._TP.values()),\n                                                                 false_positives=sum(self._FP.values()),\n                                                                 false_negatives=sum(self._GT.values())-sum(self._TP.values()))\n        all_metrics[\"micro@P\"] = precision\n        all_metrics[\"micro@R\"] = recall\n        all_metrics[\"micro@F1\"] = f1_measure\n\n        if self._num_gold_mentions == 0:\n            entity_recall = 0.0\n        else:\n            entity_recall = self._num_recalled_mentions / float(self._num_gold_mentions)\n\n        if self._num_predicted_mentions == 0:\n            entity_precision = 0.0\n        else:\n            entity_precision = self._num_recalled_mentions / float(self._num_predicted_mentions)\n\n        all_metrics['MD@R'] = entity_recall\n        all_metrics['MD@P'] = entity_precision\n        all_metrics['MD@F1'] = 2. * ((entity_precision * entity_recall) / (entity_precision + entity_recall + 1e-13))\n        all_metrics['ALLTRUE'] = self._num_gold_mentions\n        all_metrics['ALLRECALLED'] = self._num_recalled_mentions\n        all_metrics['ALLPRED'] = self._num_predicted_mentions\n        if reset:\n            self.reset()\n        return all_metrics\n\n    @staticmethod\n    def compute_prf_metrics(true_positives: int, false_positives: int, false_negatives: int):\n        \n        precision = float(true_positives) / float(true_positives + false_positives + 1e-13)\n        recall = float(true_positives) / float(true_positives + false_negatives + 1e-13)\n        f1_measure = 2. * ((precision * recall) / (precision + recall + 1e-13))\n        return precision, recall, f1_measure\n\n    @overrides\n    def reset(self):\n        \n        self._num_gold_mentions = 0\n        self._num_recalled_mentions = 0\n        self._num_predicted_mentions = 0\n        self._TP.clear()\n        self._FP.clear()\n        self._GT.clear()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:47:16.011743Z","iopub.execute_input":"2021-11-24T06:47:16.012438Z","iopub.status.idle":"2021-11-24T06:47:16.037726Z","shell.execute_reply.started":"2021-11-24T06:47:16.012396Z","shell.execute_reply":"2021-11-24T06:47:16.036526Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Model class\n---","metadata":{}},{"cell_type":"code","source":"class NERModel(nn.Module):\n    \n    def __init__(self,\n                 lr = 1e-5,\n                 dropout_rate = 0.1,\n                 batch_size = 16,\n                 tag_to_id = None,\n                 stage = 'fit',\n                 pad_token_id = 1,\n                 feature_length = 44,\n                 encoder_model = 'xlm-roberta-large',\n                 num_gpus = 1):\n        super(NERModel, self).__init__()\n\n        self.id_to_tag = {v: k for k, v in tag_to_id.items()}\n        self.tag_to_id = tag_to_id\n        self.batch_size = batch_size\n\n        self.stage = stage\n        self.num_gpus = num_gpus\n        self.target_size = len(self.id_to_tag)\n        self.feature_length = feature_length\n        \n        # set the default baseline model here\n        self.pad_token_id = pad_token_id\n\n        self.encoder_model = encoder_model\n        self.encoder = AutoModel.from_pretrained(encoder_model, return_dict = True)\n        \n        self.feedforward = nn.Linear(in_features = self.encoder.config.hidden_size + self.feature_length, \n                                     out_features = self.target_size)\n        \n        self.crf_layer = ConditionalRandomField(num_tags = self.target_size, \n                                                constraints = allowed_transitions(constraint_type = \"BIO\", \n                                                                                  labels = self.id_to_tag))\n\n        self.lr = lr\n        self.dropout = nn.Dropout(dropout_rate)\n\n        self.span_f1 = SpanF1()        \n\n    def forward(self, batch):\n        \n        tokens, tags, token_mask, metadata, features = batch\n        batch_size = tokens.size(0)\n        \n        embedded_text_input = self.encoder(input_ids=tokens, attention_mask=token_mask)\n        embedded_text_input = embedded_text_input.last_hidden_state\n        features = features.unsqueeze_(-1)\n        features = features.expand(features.shape[0], features.shape[1], embedded_text_input.shape[1])\n        features = features.reshape((features.shape[0], features.shape[2], features.shape[1]))\n        embedded_text_input = torch.cat((embedded_text_input, features), dim = 2)\n        embedded_text_input = self.dropout(F.leaky_relu(embedded_text_input))\n\n        # project the token representation for classification\n        token_scores = self.feedforward(embedded_text_input)\n   \n        # compute the log-likelihood loss and compute the best NER annotation sequence\n        output = self._compute_token_tags(token_scores=token_scores, tags=tags, token_mask=token_mask, metadata=metadata, batch_size=batch_size)\n        return output\n    \n    def _compute_token_tags(self, token_scores, tags, token_mask, metadata, batch_size):\n        \n        # compute the log-likelihood loss and compute the best NER annotation sequence\n        loss = -self.crf_layer(token_scores, tags, token_mask) / float(batch_size)\n        best_path = self.crf_layer.viterbi_tags(token_scores, token_mask)\n\n        pred_results = []\n        for i in range(batch_size):\n            tag_seq, _ = best_path[i]\n            pred_results.append(extract_spans([self.id_to_tag[x] for x in tag_seq if x in self.id_to_tag]))\n\n        self.span_f1(pred_results, metadata)\n        output = {\"loss\": loss, \"results\": self.span_f1.get_metric()}\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:47:20.928482Z","iopub.execute_input":"2021-11-24T06:47:20.928761Z","iopub.status.idle":"2021-11-24T06:47:20.947603Z","shell.execute_reply.started":"2021-11-24T06:47:20.928724Z","shell.execute_reply":"2021-11-24T06:47:20.946575Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Function to load train and validation data\n---","metadata":{}},{"cell_type":"code","source":"def dataloading():\n    train_data = get_reader(file_path=sg.train, features_file_path = sg.train_features,\n                            target_vocab=get_tagset(sg.iob_tagging), \n                            encoder_model=sg.encoder_model, max_instances=sg.max_instances,\n                            max_length=sg.max_length, feature_type = sg.feature_type)\n    dev_data = get_reader(file_path=sg.dev, features_file_path = sg.dev_features, \n                          target_vocab=get_tagset(sg.iob_tagging), \n                          encoder_model=sg.encoder_model, max_instances=sg.max_instances, \n                          max_length=sg.max_length, feature_type = sg.feature_type)\n\n    return train_data, dev_data","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:47:21.598566Z","iopub.execute_input":"2021-11-24T06:47:21.599534Z","iopub.status.idle":"2021-11-24T06:47:21.607251Z","shell.execute_reply.started":"2021-11-24T06:47:21.599489Z","shell.execute_reply":"2021-11-24T06:47:21.606121Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data, dev_data = dataloading()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:47:22.736534Z","iopub.execute_input":"2021-11-24T06:47:22.737110Z","iopub.status.idle":"2021-11-24T06:48:24.561171Z","shell.execute_reply.started":"2021-11-24T06:47:22.737076Z","shell.execute_reply":"2021-11-24T06:48:24.560073Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc35b4e689a4be98de896df2eb3a8d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b3f5022c17343c5b9bd9d980cefc889"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c1cbda4723244f6b715b81e20b5d29a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79c056f43be14d249a188850f778e867"}},"metadata":{}},{"name":"stdout","text":"Obtaining encoded_dependency_features from ../input/semeval-task-11/en_train_features.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=7650), Label(value='0 / 7650'))), …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6448cf2916c04483bd73dc137d887c9e"}},"metadata":{}},{"name":"stdout","text":"Reading file ../input/semeval-task-11/EN-English/en_train.conll\n","output_type":"stream"},{"name":"stderr","text":"15300it [00:47, 320.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Finished reading 15300 instances from file ../input/semeval-task-11/EN-English/en_train.conll\nObtaining encoded_dependency_features from ../input/semeval-task-11/en_dev_features.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=400), Label(value='0 / 400'))), HB…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2208c1844b740969684d0321e61fa74"}},"metadata":{}},{"name":"stdout","text":"Reading file ../input/semeval-task-11/EN-English/en_dev.conll\n","output_type":"stream"},{"name":"stderr","text":"800it [00:02, 299.14it/s]","output_type":"stream"},{"name":"stdout","text":"Finished reading 800 instances from file ../input/semeval-task-11/EN-English/en_dev.conll\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prepare data into batches for training and evaluation\n---","metadata":{}},{"cell_type":"code","source":"def collate_batch(batch):\n        \n        batch_ = list(zip(*batch))\n        tokens, masks, gold_spans, tags, features = batch_[0], batch_[1], batch_[2], batch_[3], batch_[4]\n\n        max_len = max([len(token) for token in tokens])\n        token_tensor = torch.empty(size = (len(tokens), max_len), \n                                   dtype = torch.long).fill_(1)\n        tag_tensor = torch.empty(size = (len(tokens), max_len), \n                                 dtype = torch.long).fill_(model.tag_to_id['O'])\n        mask_tensor = torch.zeros(size = (len(tokens), max_len), dtype = torch.bool)\n        \n        features = torch.stack(list(features), dim=0)\n            \n        for i in range(len(tokens)):\n            \n            tokens_ = tokens[i]\n            seq_len = len(tokens_)\n\n            token_tensor[i, :seq_len] = tokens_\n            tag_tensor[i, :seq_len] = tags[i]\n            mask_tensor[i, :seq_len] = masks[i]\n\n        return token_tensor, tag_tensor, mask_tensor, gold_spans, features","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:48:24.564069Z","iopub.execute_input":"2021-11-24T06:48:24.565386Z","iopub.status.idle":"2021-11-24T06:48:24.578019Z","shell.execute_reply.started":"2021-11-24T06:48:24.565334Z","shell.execute_reply":"2021-11-24T06:48:24.576681Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train_dataloader():\n    loader = DataLoader(train_data, batch_size = sg.batch_size, collate_fn = collate_batch, num_workers = 1)\n    return loader\n\ndef val_dataloader():\n    loader = DataLoader(dev_data, batch_size = sg.batch_size, collate_fn = collate_batch, num_workers = 1)\n    return loader","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:48:24.579915Z","iopub.execute_input":"2021-11-24T06:48:24.580342Z","iopub.status.idle":"2021-11-24T06:48:24.601044Z","shell.execute_reply.started":"2021-11-24T06:48:24.580296Z","shell.execute_reply":"2021-11-24T06:48:24.599514Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"training_dataloader = train_dataloader()\nvalidation_dataloader = val_dataloader()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:48:24.604054Z","iopub.execute_input":"2021-11-24T06:48:24.604477Z","iopub.status.idle":"2021-11-24T06:48:24.613472Z","shell.execute_reply.started":"2021-11-24T06:48:24.604431Z","shell.execute_reply":"2021-11-24T06:48:24.612301Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = NERModel(tag_to_id = train_data.get_target_vocab(), dropout_rate = sg.dropout, \n                 batch_size = sg.batch_size, stage = sg.stage, lr = sg.lr, feature_length = sg.feature_length,\n                         encoder_model = sg.encoder_model, num_gpus = sg.gpus)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:48:24.615026Z","iopub.execute_input":"2021-11-24T06:48:24.615701Z","iopub.status.idle":"2021-11-24T06:49:33.953437Z","shell.execute_reply.started":"2021-11-24T06:48:24.615626Z","shell.execute_reply":"2021-11-24T06:49:33.952344Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"195b4213957c434d97cf76763ddee958"}},"metadata":{}}]},{"cell_type":"code","source":"model.to(sg.device)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:49:33.955542Z","iopub.execute_input":"2021-11-24T06:49:33.955842Z","iopub.status.idle":"2021-11-24T06:49:42.958315Z","shell.execute_reply.started":"2021-11-24T06:49:33.955801Z","shell.execute_reply":"2021-11-24T06:49:42.957353Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"NERModel(\n  (encoder): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (feedforward): Linear(in_features=812, out_features=13, bias=True)\n  (crf_layer): ConditionalRandomField()\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=sg.lr)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:49:42.960003Z","iopub.execute_input":"2021-11-24T06:49:42.960526Z","iopub.status.idle":"2021-11-24T06:49:42.968109Z","shell.execute_reply.started":"2021-11-24T06:49:42.960482Z","shell.execute_reply":"2021-11-24T06:49:42.966843Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Training and Evaluation\n---","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate():\n    \n    print(\"----------------------- Training ----------------------------\")\n    print()\n    \n    # Training loop\n    for epoch_i in tqdm(range(sg.epochs)):\n\n        epoch_iterator = tqdm(training_dataloader, desc = \"Iteration\", position = 0, leave = True)\n\n        # TRAIN loop\n        model.train()\n        training_loss = 0\n\n        for step, batch in enumerate(epoch_iterator):\n            #print(batch)\n            #print(batch[4][32])\n            batch = (batch[0].to(sg.device), batch[1].to(sg.device), batch[2].to(sg.device), batch[3], batch[4].to(sg.device))\n            # forward pass\n            output = model.forward(batch)\n\n            # backward pass\n            loss = output['loss']\n            loss.backward()\n\n            # track train loss\n            training_loss += loss.item()\n\n            # gradient clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = sg.max_grad_norm)\n\n            # update parameters\n            optimizer.step()\n\n        # print train loss per epoch\n        training_loss = training_loss / len(training_dataloader)\n        print()\n        print('Epoch: {} \\tTraining Loss: {:.5f}'.format(epoch_i + 1, training_loss))\n    \n        metric_scores = model.span_f1.get_metric()\n        model.span_f1.reset()\n        \n        print()\n        print(\"Epoch: {} metrics\".format(epoch_i+1))\n        print()\n        for key, value in metric_scores.items():\n            print(\"{}: {:.5f},\".format(key, value), end = \" \")\n        print()\n    \n    print()\n    print(\"--------------------- Evaluation ---------------------\")\n    print()\n    \n    # Loop for evaluation on validation set\n    \n    epoch_iterator = tqdm(validation_dataloader, desc = \"Iteration\", position = 0, leave = True)\n    \n    validation_loss = 0\n    for step, batch in enumerate(epoch_iterator):\n        \n        batch = (batch[0].to(sg.device), batch[1].to(sg.device), batch[2].to(sg.device), batch[3], batch[4].to(sg.device))\n\n        with torch.no_grad():\n            output = model.forward(batch)\n\n        loss = output['loss']\n        validation_loss += loss.item()\n\n    validation_loss = validation_loss / len(validation_dataloader)\n    print()\n    print('Validation Loss: {:.5f}'.format(validation_loss))\n    print()\n    metric_scores = model.span_f1.get_metric()\n    model.span_f1.reset()\n    print()\n    print(\"Metrics on validation set\")\n    print()\n    for key, value in metric_scores.items():\n        print(\"{}: {:.5f},\".format(key, value), end = \" \")\n    print()\n    print()\n    torch.save(model, \"./\" + sg.model_name + \"_\" + str(sg.batch_size) + \"_\" + str(sg.lr) + \".pt\")\n    print(\"Saved the model\")","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:49:42.970285Z","iopub.execute_input":"2021-11-24T06:49:42.970627Z","iopub.status.idle":"2021-11-24T06:49:42.992356Z","shell.execute_reply.started":"2021-11-24T06:49:42.970583Z","shell.execute_reply":"2021-11-24T06:49:42.990999Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_and_evaluate()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:49:42.993954Z","iopub.execute_input":"2021-11-24T06:49:42.994788Z","iopub.status.idle":"2021-11-24T06:57:16.888852Z","shell.execute_reply.started":"2021-11-24T06:49:42.994741Z","shell.execute_reply":"2021-11-24T06:57:16.887567Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"----------------------- Training ----------------------------\n\n","output_type":"stream"},{"name":"stderr","text":"Iteration: 100%|██████████| 479/479 [02:29<00:00,  3.20it/s]\n 33%|███▎      | 1/3 [02:29<04:59, 149.50s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 1 \tTraining Loss: 19.45221\n\nEpoch: 1 metrics\n\nP@CORP: 0.20664, R@CORP: 0.32401, F1@CORP: 0.25235, P@PER: 0.55120, R@PER: 0.66630, F1@PER: 0.60331, P@LOC: 0.46962, R@LOC: 0.51219, F1@LOC: 0.48998, P@PROD: 0.22087, R@PROD: 0.12385, F1@PROD: 0.15870, P@GRP: 0.31662, R@GRP: 0.39793, F1@GRP: 0.35265, P@CW: 0.44152, R@CW: 0.25053, F1@CW: 0.31967, micro@P: 0.39310, micro@R: 0.41545, micro@F1: 0.40396, MD@R: 0.51463, MD@P: 0.48694, MD@F1: 0.50040, ALLTRUE: 23553.00000, ALLRECALLED: 12121.00000, ALLPRED: 24892.00000, \n","output_type":"stream"},{"name":"stderr","text":"Iteration: 100%|██████████| 479/479 [02:29<00:00,  3.20it/s]\n 67%|██████▋   | 2/3 [04:59<02:29, 149.71s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2 \tTraining Loss: 5.31680\n\nEpoch: 2 metrics\n\nP@CORP: 0.66476, R@CORP: 0.67117, F1@CORP: 0.66795, P@PER: 0.89349, R@PER: 0.91866, F1@PER: 0.90590, P@LOC: 0.81334, R@LOC: 0.81809, F1@LOC: 0.81571, P@PROD: 0.47260, R@PROD: 0.47212, F1@PROD: 0.47236, P@GRP: 0.73007, R@GRP: 0.69756, F1@GRP: 0.71345, P@CW: 0.59101, R@CW: 0.57463, F1@CW: 0.58270, micro@P: 0.72345, micro@R: 0.72173, micro@F1: 0.72259, MD@R: 0.79629, MD@P: 0.79819, MD@F1: 0.79724, ALLTRUE: 23553.00000, ALLRECALLED: 18755.00000, ALLPRED: 23497.00000, \n","output_type":"stream"},{"name":"stderr","text":"Iteration: 100%|██████████| 479/479 [02:28<00:00,  3.22it/s]\n100%|██████████| 3/3 [07:28<00:00, 149.43s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3 \tTraining Loss: 3.61308\n\nEpoch: 3 metrics\n\nP@CORP: 0.75785, R@CORP: 0.76760, F1@CORP: 0.76270, P@PER: 0.92749, R@PER: 0.94089, F1@PER: 0.93414, P@LOC: 0.86488, R@LOC: 0.87497, F1@LOC: 0.86990, P@PROD: 0.59868, R@PROD: 0.61854, F1@PROD: 0.60845, P@GRP: 0.79753, R@GRP: 0.76001, F1@GRP: 0.77832, P@CW: 0.70059, R@CW: 0.69350, F1@CW: 0.69703, micro@P: 0.79554, micro@R: 0.79773, micro@F1: 0.79663, MD@R: 0.85386, MD@P: 0.85151, MD@F1: 0.85268, ALLTRUE: 23553.00000, ALLRECALLED: 20111.00000, ALLPRED: 23618.00000, \n\n--------------------- Evaluation ---------------------\n\n","output_type":"stream"},{"name":"stderr","text":"Iteration: 100%|██████████| 25/25 [00:03<00:00,  6.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Loss: 5.51213\n\n\nMetrics on validation set\n\nP@CORP: 0.78528, R@CORP: 0.66321, F1@CORP: 0.71910, P@PER: 0.88562, R@PER: 0.93448, F1@PER: 0.90940, P@LOC: 0.73801, R@LOC: 0.85470, F1@LOC: 0.79208, P@PROD: 0.54348, R@PROD: 0.51020, F1@PROD: 0.52632, P@GRP: 0.76506, R@GRP: 0.66842, F1@GRP: 0.71348, P@CW: 0.57831, R@CW: 0.54545, F1@CW: 0.56140, micro@P: 0.74132, micro@R: 0.72927, micro@F1: 0.73525, MD@R: 0.80894, MD@P: 0.82231, MD@F1: 0.81557, ALLTRUE: 1230.00000, ALLRECALLED: 995.00000, ALLPRED: 1210.00000, \n\nSaved the model\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}