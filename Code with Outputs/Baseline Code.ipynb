{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import required libraries\n---","metadata":{}},{"cell_type":"code","source":"import os\nimport gzip\nimport itertools\nimport logging\nimport torch\nfrom typing import List, Any\nimport torch.nn.functional as F\nimport numpy as np\nfrom allennlp.modules import ConditionalRandomField\nfrom allennlp.modules.conditional_random_field import allowed_transitions\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom transformers import get_linear_schedule_with_warmup, AutoModel\nfrom torch.utils.data import Dataset\nfrom transformers import AutoTokenizer\nfrom collections import defaultdict\nfrom typing import Set\nfrom overrides import overrides\nfrom allennlp.training.metrics.metric import Metric\nimport argparse\nimport time\nfrom pytorch_lightning import seed_everything\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, EarlyStopping\nimport warnings\nfrom tqdm import tqdm\nimport random as rn\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:27:51.376717Z","iopub.execute_input":"2021-11-24T06:27:51.377471Z","iopub.status.idle":"2021-11-24T06:28:05.993437Z","shell.execute_reply.started":"2021-11-24T06:27:51.377373Z","shell.execute_reply":"2021-11-24T06:28:05.992409Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"conll_iob = {'B-ORG': 0, 'I-ORG': 1, 'B-MISC': 2, 'I-MISC': 3, 'B-LOC': 4, \n             'I-LOC': 5, 'B-PER': 6, 'I-PER': 7, 'O': 8}\nwnut_iob = {'B-CORP': 0, 'I-CORP': 1, 'B-CW': 2, 'I-CW': 3, 'B-GRP': 4, \n            'I-GRP': 5, 'B-LOC': 6, 'I-LOC': 7, 'B-PER': 8, 'I-PER': 9, \n            'B-PROD': 10, 'I-PROD': 11, 'O': 12}\nSEED = 42\nrn.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:05.995658Z","iopub.execute_input":"2021-11-24T06:28:05.995933Z","iopub.status.idle":"2021-11-24T06:28:06.010832Z","shell.execute_reply.started":"2021-11-24T06:28:05.995897Z","shell.execute_reply":"2021-11-24T06:28:06.010131Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Loading Functions and Class\n---","metadata":{}},{"cell_type":"code","source":"def get_ner_reader(data):\n    \n    # 'fields' contains 4 lists \n    # The first list is the list of words present in the sentence\n    # The last list is the list of ner tags of the words.\n    \n    fin = gzip.open(data, 'rt') if data.endswith('.gz') else open(data, 'rt')\n    \n    for is_divider, lines in itertools.groupby(fin, _is_divider):\n        \n        if is_divider:\n            continue\n        \n        fields = [line.strip().split() for line in lines]\n        fields = [list(field) for field in zip(*fields)]\n        \n        yield fields\n\n# Function to assign the new tags \ndef _assign_ner_tags(ner_tag, rep_):\n    \n    ner_tags_rep = []\n    token_masks = []\n\n    sub_token_len = len(rep_)\n    token_masks.extend([True] * sub_token_len)\n    \n    if ner_tag[0] == 'B':\n        \n        in_tag = 'I' + ner_tag[1:]\n        ner_tags_rep.append(ner_tag)\n        ner_tags_rep.extend([in_tag] * (sub_token_len - 1))\n    \n    else:\n        ner_tags_rep.extend([ner_tag] * sub_token_len)\n    \n    return ner_tags_rep, token_masks\n\n# Function to extract spans (BI spans) and store in a dictionary\ndef extract_spans(tags):\n    \n    cur_tag = None\n    cur_start = None\n    gold_spans = {}\n\n    def _save_span(_cur_tag, _cur_start, _cur_id, _gold_spans):\n        \n        if _cur_start is None:\n            return _gold_spans\n        \n        _gold_spans[(_cur_start, _cur_id - 1)] = _cur_tag  # inclusive start & end, accord with conll-coref settings\n        \n        return _gold_spans\n\n    # iterate over the tags\n    for _id, nt in enumerate(tags):\n        \n        indicator = nt[0]\n        \n        if indicator == 'B':\n            gold_spans = _save_span(cur_tag, cur_start, _id, gold_spans)\n            cur_start = _id\n            cur_tag = nt[2:]\n            pass\n        \n        elif indicator == 'I':\n            # do nothing\n            pass\n        \n        elif indicator == 'O':\n            gold_spans = _save_span(cur_tag, cur_start, _id, gold_spans)\n            cur_tag = 'O'\n            cur_start = _id\n            pass\n    \n    _save_span(cur_tag, cur_start, _id + 1, gold_spans)\n    \n    return gold_spans\n\n\ndef _is_divider(line: str) -> bool:\n    \n    empty_line = line.strip() == ''\n    \n    if empty_line:\n        return True\n\n    first_token = line.split()[0]\n    if first_token == \"-DOCSTART-\" or line.startswith('# id'):  # pylint: disable=simplifiable-if-statement\n        return True\n\n    return False","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.012497Z","iopub.execute_input":"2021-11-24T06:28:06.012782Z","iopub.status.idle":"2021-11-24T06:28:06.028276Z","shell.execute_reply.started":"2021-11-24T06:28:06.012748Z","shell.execute_reply":"2021-11-24T06:28:06.027512Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CoNLLReader(Dataset):\n    \n    def __init__(self, max_instances = -1, max_length = 50, target_vocab = None, \n                 pretrained_dir = '', encoder_model = 'xlm-roberta-large'):\n        \n        self._max_instances = max_instances\n        self._max_length = max_length\n\n        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_dir + encoder_model)\n\n        self.pad_token = self.tokenizer.special_tokens_map['pad_token']\n        self.pad_token_id = self.tokenizer.get_vocab()['pad']\n        self.sep_token = self.tokenizer.special_tokens_map['sep_token']\n\n        self.label_to_id = {} if target_vocab is None else target_vocab\n        self.instances = []\n\n    def get_target_size(self):\n        return len(set(self.label_to_id.values()))\n\n    def get_target_vocab(self):\n        return self.label_to_id\n\n    def __len__(self):\n        return len(self.instances)\n\n    def __getitem__(self, item):\n        return self.instances[item]\n\n    def read_data(self, data):\n        \n        dataset_name = data if isinstance(data, str) else 'dataframe'\n\n        print(\"Reading file {}\".format(dataset_name))\n        instance_idx = 0\n        \n        for fields in tqdm(get_ner_reader(data = data)):\n            \n            if self._max_instances != -1 and instance_idx > self._max_instances:\n                break\n            \n            sentence_str, tokens_sub_rep, token_masks_rep, coded_ner_, gold_spans_ = self.parse_line_for_ner(fields = fields)\n            \n            tokens_tensor = torch.tensor(tokens_sub_rep, dtype = torch.long)\n            tag_tensor = torch.tensor(coded_ner_, dtype = torch.long).unsqueeze(0)\n            token_masks_rep = torch.tensor(token_masks_rep)\n\n            self.instances.append((tokens_tensor, token_masks_rep, gold_spans_, tag_tensor))\n            instance_idx += 1\n                    \n        print(\"Finished reading {:d} instances from file {}\".format(len(self.instances), dataset_name))\n    \n    def parse_line_for_ner(self, fields):\n        \n        tokens_, ner_tags = fields[0], fields[-1]\n\n        sentence_str, tokens_sub_rep, ner_tags_rep, token_masks_rep = self.parse_tokens_for_ner(tokens_, ner_tags)\n        gold_spans_ = extract_spans(ner_tags_rep)\n        coded_ner_ = [self.label_to_id[tag] for tag in ner_tags_rep]\n\n        return sentence_str, tokens_sub_rep, token_masks_rep, coded_ner_, gold_spans_\n\n    def parse_tokens_for_ner(self, tokens_, ner_tags):\n        \n        sentence_str = ''\n        tokens_sub_rep, ner_tags_rep = [self.pad_token_id], ['O']\n        \n        for idx, token in enumerate(tokens_):\n            \n            if self._max_length != -1 and len(tokens_sub_rep) > self._max_length:\n                break\n            \n            sentence_str += ' ' + ' '.join(self.tokenizer.tokenize(token.lower()))\n            rep_ = self.tokenizer(token.lower())['input_ids']\n            rep_ = rep_[1:-1]\n            tokens_sub_rep.extend(rep_)\n\n            # if we have a NER here, in the case of B, the first NER tag is the B tag, the rest are I tags.\n            ner_tag = ner_tags[idx]\n            tags, masks = _assign_ner_tags(ner_tag, rep_)\n            ner_tags_rep.extend(tags)\n\n        tokens_sub_rep.append(self.pad_token_id)\n        ner_tags_rep.append('O')\n        token_masks_rep = [True] * len(tokens_sub_rep)\n        \n        return sentence_str, tokens_sub_rep, ner_tags_rep, token_masks_rep","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.031055Z","iopub.execute_input":"2021-11-24T06:28:06.031773Z","iopub.status.idle":"2021-11-24T06:28:06.050430Z","shell.execute_reply.started":"2021-11-24T06:28:06.031734Z","shell.execute_reply":"2021-11-24T06:28:06.049682Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def get_tagset(tagging_scheme):\n    if 'conll' in tagging_scheme:\n        return conll_iob\n    return wnut_iob\n\ndef get_reader(file_path, max_instances=-1, max_length=50, target_vocab=None, encoder_model='xlm-roberta-large'):\n    if file_path is None:\n        return None\n    reader = CoNLLReader(max_instances=max_instances, max_length=max_length, target_vocab=target_vocab, encoder_model=encoder_model)\n    reader.read_data(file_path)\n\n    return reader","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.052083Z","iopub.execute_input":"2021-11-24T06:28:06.052403Z","iopub.status.idle":"2021-11-24T06:28:06.064095Z","shell.execute_reply.started":"2021-11-24T06:28:06.052365Z","shell.execute_reply":"2021-11-24T06:28:06.063310Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Args Class\n---","metadata":{}},{"cell_type":"code","source":"class Args():\n    \n    def __init__(self):\n        \n        self.train = '../input/semeval-task-11/EN-English/en_train.conll'\n        self.test = '../input/semeval-task-11/EN-English/en_dev.conll'\n        self.dev = '../input/semeval-task-11/EN-English/en_dev.conll'\n        \n        self.out_dir = './'\n        self.iob_tagging = 'wnut'\n        \n        self.max_instances = -1\n        self.max_length = 50\n        \n        # encoder_model options: xlm-roberta-base or ai4bharat/indic-bert or bert-base-multilingual-cased\n        self.encoder_model = 'bert-base-multilingual-cased'\n        self.model = './'\n        self.model_name = 'bert-base-multilingual-cased'\n        self.stage = 'fit'\n        self.prefix = 'test'\n\n        self.batch_size = 8\n        self.gpus = 1\n        self.device = 'cuda'\n        self.epochs = 3\n        self.lr = 1e-5\n        self.dropout = 0.1\n        self.max_grad_norm = 1.0","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.066369Z","iopub.execute_input":"2021-11-24T06:28:06.066783Z","iopub.status.idle":"2021-11-24T06:28:06.074505Z","shell.execute_reply.started":"2021-11-24T06:28:06.066747Z","shell.execute_reply":"2021-11-24T06:28:06.073784Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"sg = Args()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.075739Z","iopub.execute_input":"2021-11-24T06:28:06.076062Z","iopub.status.idle":"2021-11-24T06:28:06.086408Z","shell.execute_reply.started":"2021-11-24T06:28:06.076019Z","shell.execute_reply":"2021-11-24T06:28:06.085638Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Metric\n---","metadata":{}},{"cell_type":"code","source":"class SpanF1(Metric):\n    \n    def __init__(self, non_entity_labels = ['O']) -> None:\n        \n        self._num_gold_mentions = 0\n        self._num_recalled_mentions = 0\n        self._num_predicted_mentions = 0\n        self._TP, self._FP, self._GT = defaultdict(int), defaultdict(int), defaultdict(int)\n        self.non_entity_labels = set(non_entity_labels)\n\n    @overrides\n    def __call__(self, batched_predicted_spans, batched_gold_spans, sentences = None):\n        \n        non_entity_labels = self.non_entity_labels\n\n        for predicted_spans, gold_spans in zip(batched_predicted_spans, batched_gold_spans):\n            gold_spans_set = set([x for x, y in gold_spans.items() if y not in non_entity_labels])\n            pred_spans_set = set([x for x, y in predicted_spans.items() if y not in non_entity_labels])\n\n            self._num_gold_mentions += len(gold_spans_set)\n            self._num_recalled_mentions += len(gold_spans_set & pred_spans_set)\n            self._num_predicted_mentions += len(pred_spans_set)\n\n            for ky, val in gold_spans.items():\n                if val not in non_entity_labels:\n                    self._GT[val] += 1\n\n            for ky, val in predicted_spans.items():\n                if val in non_entity_labels:\n                    continue\n                if ky in gold_spans and val == gold_spans[ky]:\n                    self._TP[val] += 1\n                else:\n                    self._FP[val] += 1\n\n    @overrides\n    def get_metric(self, reset: bool = False) -> float:\n        \n        all_tags: Set[str] = set()\n        all_tags.update(self._TP.keys())\n        all_tags.update(self._FP.keys())\n        all_tags.update(self._GT.keys())\n        all_metrics = {}\n\n        for tag in all_tags:\n            precision, recall, f1_measure = self.compute_prf_metrics(true_positives=self._TP[tag],\n                                                                     false_negatives=self._GT[tag] - self._TP[tag],\n                                                                     false_positives=self._FP[tag])\n            all_metrics['P@{}'.format(tag)] = precision\n            all_metrics['R@{}'.format(tag)] = recall\n            all_metrics['F1@{}'.format(tag)] = f1_measure\n\n        # Compute the precision, recall and f1 for all spans jointly.\n        precision, recall, f1_measure = self.compute_prf_metrics(true_positives=sum(self._TP.values()),\n                                                                 false_positives=sum(self._FP.values()),\n                                                                 false_negatives=sum(self._GT.values())-sum(self._TP.values()))\n        all_metrics[\"micro@P\"] = precision\n        all_metrics[\"micro@R\"] = recall\n        all_metrics[\"micro@F1\"] = f1_measure\n\n        if self._num_gold_mentions == 0:\n            entity_recall = 0.0\n        else:\n            entity_recall = self._num_recalled_mentions / float(self._num_gold_mentions)\n\n        if self._num_predicted_mentions == 0:\n            entity_precision = 0.0\n        else:\n            entity_precision = self._num_recalled_mentions / float(self._num_predicted_mentions)\n\n        all_metrics['MD@R'] = entity_recall\n        all_metrics['MD@P'] = entity_precision\n        all_metrics['MD@F1'] = 2. * ((entity_precision * entity_recall) / (entity_precision + entity_recall + 1e-13))\n        all_metrics['ALLTRUE'] = self._num_gold_mentions\n        all_metrics['ALLRECALLED'] = self._num_recalled_mentions\n        all_metrics['ALLPRED'] = self._num_predicted_mentions\n        if reset:\n            self.reset()\n        return all_metrics\n\n    @staticmethod\n    def compute_prf_metrics(true_positives: int, false_positives: int, false_negatives: int):\n        \n        precision = float(true_positives) / float(true_positives + false_positives + 1e-13)\n        recall = float(true_positives) / float(true_positives + false_negatives + 1e-13)\n        f1_measure = 2. * ((precision * recall) / (precision + recall + 1e-13))\n        return precision, recall, f1_measure\n\n    @overrides\n    def reset(self):\n        \n        self._num_gold_mentions = 0\n        self._num_recalled_mentions = 0\n        self._num_predicted_mentions = 0\n        self._TP.clear()\n        self._FP.clear()\n        self._GT.clear()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.087668Z","iopub.execute_input":"2021-11-24T06:28:06.088341Z","iopub.status.idle":"2021-11-24T06:28:06.110414Z","shell.execute_reply.started":"2021-11-24T06:28:06.088308Z","shell.execute_reply":"2021-11-24T06:28:06.109711Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Model class\n---","metadata":{}},{"cell_type":"code","source":"class NERModel(nn.Module):\n    \n    def __init__(self,\n                 lr = 1e-5,\n                 dropout_rate = 0.1,\n                 batch_size = 16,\n                 tag_to_id = None,\n                 stage = 'fit',\n                 pad_token_id = 1,\n                 encoder_model = 'xlm-roberta-large',\n                 num_gpus = 1):\n        super(NERModel, self).__init__()\n\n        self.id_to_tag = {v: k for k, v in tag_to_id.items()}\n        self.tag_to_id = tag_to_id\n        self.batch_size = batch_size\n\n        self.stage = stage\n        self.num_gpus = num_gpus\n        self.target_size = len(self.id_to_tag)\n\n        # set the default baseline model here\n        self.pad_token_id = pad_token_id\n\n        self.encoder_model = encoder_model\n        self.encoder = AutoModel.from_pretrained(encoder_model, return_dict = True)\n\n        self.feedforward = nn.Linear(in_features = self.encoder.config.hidden_size, \n                                     out_features = self.target_size)\n        \n        self.crf_layer = ConditionalRandomField(num_tags = self.target_size, \n                                                constraints = allowed_transitions(constraint_type = \"BIO\", \n                                                                                  labels = self.id_to_tag))\n\n        self.lr = lr\n        self.dropout = nn.Dropout(dropout_rate)\n\n        self.span_f1 = SpanF1()        \n\n    def forward(self, batch):\n        \n        tokens, tags, token_mask, metadata = batch\n        batch_size = tokens.size(0)\n\n        embedded_text_input = self.encoder(input_ids=tokens, attention_mask=token_mask)\n        embedded_text_input = embedded_text_input.last_hidden_state\n        embedded_text_input = self.dropout(F.leaky_relu(embedded_text_input))\n\n        # project the token representation for classification\n        token_scores = self.feedforward(embedded_text_input)\n\n        # compute the log-likelihood loss and compute the best NER annotation sequence\n        output = self._compute_token_tags(token_scores=token_scores, tags=tags, token_mask=token_mask, metadata=metadata, batch_size=batch_size)\n        return output\n    \n    def _compute_token_tags(self, token_scores, tags, token_mask, metadata, batch_size):\n        \n        # compute the log-likelihood loss and compute the best NER annotation sequence\n        loss = -self.crf_layer(token_scores, tags, token_mask) / float(batch_size)\n        best_path = self.crf_layer.viterbi_tags(token_scores, token_mask)\n\n        pred_results = []\n        for i in range(batch_size):\n            tag_seq, _ = best_path[i]\n            pred_results.append(extract_spans([self.id_to_tag[x] for x in tag_seq if x in self.id_to_tag]))\n\n        self.span_f1(pred_results, metadata)\n        output = {\"loss\": loss, \"results\": self.span_f1.get_metric()}\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.111859Z","iopub.execute_input":"2021-11-24T06:28:06.112124Z","iopub.status.idle":"2021-11-24T06:28:06.129062Z","shell.execute_reply.started":"2021-11-24T06:28:06.112089Z","shell.execute_reply":"2021-11-24T06:28:06.128357Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Function to load train and validation data\n---","metadata":{}},{"cell_type":"code","source":"def dataloading():\n    train_data = get_reader(file_path=sg.train, target_vocab=get_tagset(sg.iob_tagging), \n                            encoder_model=sg.encoder_model, max_instances=sg.max_instances,\n                            max_length=sg.max_length)\n    dev_data = get_reader(file_path=sg.dev, target_vocab=get_tagset(sg.iob_tagging), \n                          encoder_model=sg.encoder_model, max_instances=sg.max_instances, \n                          max_length=sg.max_length)\n\n    return train_data, dev_data","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.131724Z","iopub.execute_input":"2021-11-24T06:28:06.132027Z","iopub.status.idle":"2021-11-24T06:28:06.139561Z","shell.execute_reply.started":"2021-11-24T06:28:06.131993Z","shell.execute_reply":"2021-11-24T06:28:06.138810Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_data, dev_data = dataloading()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:06.140934Z","iopub.execute_input":"2021-11-24T06:28:06.142096Z","iopub.status.idle":"2021-11-24T06:28:42.179143Z","shell.execute_reply.started":"2021-11-24T06:28:06.141991Z","shell.execute_reply":"2021-11-24T06:28:42.178171Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4133c06971b4fcea6e2d2c709f5dd42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd0d1a06e3704b7087d6b255b2118dfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9446b277cc4c4e6a9785c15a8a2c5d94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7375ffed3309456ebd2886e843f6671c"}},"metadata":{}},{"name":"stdout","text":"Reading file ../input/semeval-task-11/EN-English/en_train.conll\n","output_type":"stream"},{"name":"stderr","text":"15300it [00:30, 495.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Finished reading 15300 instances from file ../input/semeval-task-11/EN-English/en_train.conll\nReading file ../input/semeval-task-11/EN-English/en_dev.conll\n","output_type":"stream"},{"name":"stderr","text":"800it [00:01, 506.34it/s]","output_type":"stream"},{"name":"stdout","text":"Finished reading 800 instances from file ../input/semeval-task-11/EN-English/en_dev.conll\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Prepare data into batches for training and evaluation\n---","metadata":{}},{"cell_type":"code","source":"def collate_batch(batch):\n        \n        batch_ = list(zip(*batch))\n        tokens, masks, gold_spans, tags = batch_[0], batch_[1], batch_[2], batch_[3]\n\n        max_len = max([len(token) for token in tokens])\n        token_tensor = torch.empty(size = (len(tokens), max_len), \n                                   dtype = torch.long).fill_(1)\n        tag_tensor = torch.empty(size = (len(tokens), max_len), \n                                 dtype = torch.long).fill_(model.tag_to_id['O'])\n        mask_tensor = torch.zeros(size = (len(tokens), max_len), dtype = torch.bool)\n\n        for i in range(len(tokens)):\n            \n            tokens_ = tokens[i]\n            seq_len = len(tokens_)\n\n            token_tensor[i, :seq_len] = tokens_\n            tag_tensor[i, :seq_len] = tags[i]\n            mask_tensor[i, :seq_len] = masks[i]\n\n        return token_tensor, tag_tensor, mask_tensor, gold_spans","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:42.180604Z","iopub.execute_input":"2021-11-24T06:28:42.180953Z","iopub.status.idle":"2021-11-24T06:28:42.192215Z","shell.execute_reply.started":"2021-11-24T06:28:42.180914Z","shell.execute_reply":"2021-11-24T06:28:42.191316Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train_dataloader():\n    loader = DataLoader(train_data, batch_size = sg.batch_size, collate_fn = collate_batch, num_workers = 1)\n    return loader\n\ndef val_dataloader():\n    loader = DataLoader(dev_data, batch_size = sg.batch_size, collate_fn = collate_batch, num_workers = 1)\n    return loader","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:42.193945Z","iopub.execute_input":"2021-11-24T06:28:42.194797Z","iopub.status.idle":"2021-11-24T06:28:42.215300Z","shell.execute_reply.started":"2021-11-24T06:28:42.194757Z","shell.execute_reply":"2021-11-24T06:28:42.214560Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"training_dataloader = train_dataloader()\nvalidation_dataloader = val_dataloader()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:42.218097Z","iopub.execute_input":"2021-11-24T06:28:42.218764Z","iopub.status.idle":"2021-11-24T06:28:42.223795Z","shell.execute_reply.started":"2021-11-24T06:28:42.218723Z","shell.execute_reply":"2021-11-24T06:28:42.222982Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = NERModel(tag_to_id = train_data.get_target_vocab(), dropout_rate = sg.dropout, \n                 batch_size = sg.batch_size, stage = sg.stage, lr = sg.lr,\n                         encoder_model = sg.encoder_model, num_gpus = sg.gpus)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:28:42.225273Z","iopub.execute_input":"2021-11-24T06:28:42.225572Z","iopub.status.idle":"2021-11-24T06:29:25.197400Z","shell.execute_reply.started":"2021-11-24T06:28:42.225537Z","shell.execute_reply":"2021-11-24T06:29:25.196670Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d67a71f704e24a80be9e8a2d0b7a8353"}},"metadata":{}}]},{"cell_type":"code","source":"model.to(sg.device)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:29:25.198950Z","iopub.execute_input":"2021-11-24T06:29:25.199224Z","iopub.status.idle":"2021-11-24T06:29:34.305152Z","shell.execute_reply.started":"2021-11-24T06:29:25.199188Z","shell.execute_reply":"2021-11-24T06:29:34.304362Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"NERModel(\n  (encoder): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (feedforward): Linear(in_features=768, out_features=13, bias=True)\n  (crf_layer): ConditionalRandomField()\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=sg.lr)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:29:34.306364Z","iopub.execute_input":"2021-11-24T06:29:34.307075Z","iopub.status.idle":"2021-11-24T06:29:34.313179Z","shell.execute_reply.started":"2021-11-24T06:29:34.307035Z","shell.execute_reply":"2021-11-24T06:29:34.312560Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Training and Evaluation\n---","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate():\n    \n    print(\"----------------------- Training ----------------------------\")\n    print()\n    \n    # Training loop\n    for epoch_i in tqdm(range(sg.epochs)):\n\n        epoch_iterator = tqdm(training_dataloader, desc = \"Iteration\", position = 0, leave = True)\n\n        # TRAIN loop\n        model.train()\n        training_loss = 0\n\n        for step, batch in enumerate(epoch_iterator):\n            #print(batch)\n            batch = (batch[0].to(sg.device), batch[1].to(sg.device), batch[2].to(sg.device), batch[3])\n            # forward pass\n            output = model.forward(batch)\n\n            # backward pass\n            loss = output['loss']\n            loss.backward()\n\n            # track train loss\n            training_loss += loss.item()\n\n            # gradient clipping\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = sg.max_grad_norm)\n\n            # update parameters\n            optimizer.step()\n\n        # print train loss per epoch\n        training_loss = training_loss / len(training_dataloader)\n        print()\n        print('Epoch: {} \\tTraining Loss: {:.5f}'.format(epoch_i + 1, training_loss))\n    \n        metric_scores = model.span_f1.get_metric()\n        model.span_f1.reset()\n        \n        print()\n        print(\"Epoch: {} metrics\".format(epoch_i+1))\n        print()\n        for key, value in metric_scores.items():\n            print(\"{}: {:.5f},\".format(key, value), end = \" \")\n        print()\n    \n    print()\n    print(\"--------------------- Evaluation ---------------------\")\n    print()\n    \n    # Loop for evaluation on validation set\n    \n    epoch_iterator = tqdm(validation_dataloader, desc = \"Iteration\", position = 0, leave = True)\n    \n    validation_loss = 0\n    for step, batch in enumerate(epoch_iterator):\n    \n        batch = (batch[0].to(sg.device), batch[1].to(sg.device), batch[2].to(sg.device), batch[3])\n\n        with torch.no_grad():\n            output = model.forward(batch)\n\n        loss = output['loss']\n        validation_loss += loss.item()\n\n    validation_loss = validation_loss / len(validation_dataloader)\n    print()\n    print('Validation Loss: {:.5f}'.format(validation_loss))\n    print()\n    metric_scores = model.span_f1.get_metric()\n    model.span_f1.reset()\n    print()\n    print(\"Metrics on validation set\")\n    print()\n    for key, value in metric_scores.items():\n        print(\"{}: {:.5f},\".format(key, value), end = \" \")\n    print()\n    print()\n    torch.save(model, \"./\" + sg.model_name + \"_\" + str(sg.batch_size) + \"_\" + str(sg.lr) + \".pt\")\n    print(\"Saved the model\")","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:29:34.314351Z","iopub.execute_input":"2021-11-24T06:29:34.314762Z","iopub.status.idle":"2021-11-24T06:29:34.354295Z","shell.execute_reply.started":"2021-11-24T06:29:34.314725Z","shell.execute_reply":"2021-11-24T06:29:34.353445Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_and_evaluate()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:29:51.042080Z","iopub.execute_input":"2021-11-24T06:29:51.043009Z","iopub.status.idle":"2021-11-24T06:41:43.498189Z","shell.execute_reply.started":"2021-11-24T06:29:51.042959Z","shell.execute_reply":"2021-11-24T06:41:43.497255Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"----------------------- Training ----------------------------\n\n","output_type":"stream"},{"name":"stderr","text":"Iteration: 100%|██████████| 1913/1913 [03:56<00:00,  8.08it/s]\n 33%|███▎      | 1/3 [03:56<07:53, 236.81s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 1 \tTraining Loss: 7.89017\n\nEpoch: 1 metrics\n\nP@GRP: 0.55956, R@GRP: 0.58667, F1@GRP: 0.57280, P@CORP: 0.62784, R@CORP: 0.50595, F1@CORP: 0.56034, P@PER: 0.81113, R@PER: 0.85307, F1@PER: 0.83157, P@PROD: 0.50071, R@PROD: 0.35990, F1@PROD: 0.41879, P@LOC: 0.76736, R@LOC: 0.70931, F1@LOC: 0.73720, P@CW: 0.54586, R@CW: 0.46162, F1@CW: 0.50022, micro@P: 0.66835, micro@R: 0.61398, micro@F1: 0.64001, MD@R: 0.71137, MD@P: 0.77437, MD@F1: 0.74154, ALLTRUE: 23553.00000, ALLRECALLED: 16755.00000, ALLPRED: 21637.00000, \n","output_type":"stream"},{"name":"stderr","text":"Iteration: 100%|██████████| 1913/1913 [03:55<00:00,  8.12it/s]\n 67%|██████▋   | 2/3 [07:52<03:56, 236.09s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 2 \tTraining Loss: 3.87876\n\nEpoch: 2 metrics\n\nP@GRP: 0.77601, R@GRP: 0.73929, F1@GRP: 0.75721, P@CORP: 0.72664, R@CORP: 0.73738, F1@CORP: 0.73197, P@PER: 0.91764, R@PER: 0.93515, F1@PER: 0.92631, P@PROD: 0.63630, R@PROD: 0.60691, F1@PROD: 0.62126, P@LOC: 0.85540, R@LOC: 0.84809, F1@LOC: 0.85173, P@CW: 0.66962, R@CW: 0.66498, F1@CW: 0.66729, micro@P: 0.78522, micro@R: 0.77782, micro@F1: 0.78150, MD@R: 0.84257, MD@P: 0.85059, MD@F1: 0.84656, ALLTRUE: 23553.00000, ALLRECALLED: 19845.00000, ALLPRED: 23331.00000, \n","output_type":"stream"},{"name":"stderr","text":"Iteration: 100%|██████████| 1913/1913 [03:54<00:00,  8.15it/s]\n100%|██████████| 3/3 [11:47<00:00, 235.70s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch: 3 \tTraining Loss: 2.63973\n\nEpoch: 3 metrics\n\nP@GRP: 0.83285, R@GRP: 0.80650, F1@GRP: 0.81946, P@CORP: 0.79968, R@CORP: 0.81099, F1@CORP: 0.80530, P@PER: 0.94541, R@PER: 0.95627, F1@PER: 0.95081, P@PROD: 0.71511, R@PROD: 0.72049, F1@PROD: 0.71779, P@LOC: 0.89874, R@LOC: 0.89519, F1@LOC: 0.89696, P@CW: 0.76452, R@CW: 0.76146, F1@CW: 0.76299, micro@P: 0.84231, micro@R: 0.84163, micro@F1: 0.84197, MD@R: 0.89097, MD@P: 0.89169, MD@F1: 0.89133, ALLTRUE: 23553.00000, ALLRECALLED: 20985.00000, ALLPRED: 23534.00000, \n\n--------------------- Evaluation ---------------------\n\n","output_type":"stream"},{"name":"stderr","text":"Iteration: 100%|██████████| 100/100 [00:03<00:00, 25.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Loss: 5.16857\n\n\nMetrics on validation set\n\nP@GRP: 0.79545, R@GRP: 0.73684, F1@GRP: 0.76503, P@CORP: 0.80124, R@CORP: 0.66839, F1@CORP: 0.72881, P@PER: 0.88925, R@PER: 0.94138, F1@PER: 0.91457, P@PROD: 0.65354, R@PROD: 0.56463, F1@PROD: 0.60584, P@LOC: 0.74170, R@LOC: 0.85897, F1@LOC: 0.79604, P@CW: 0.62570, R@CW: 0.63636, F1@CW: 0.63099, micro@P: 0.76822, micro@R: 0.76260, micro@F1: 0.76540, MD@R: 0.84065, MD@P: 0.84685, MD@F1: 0.84374, ALLTRUE: 1230.00000, ALLRECALLED: 1034.00000, ALLPRED: 1221.00000, \n\nSaved the model\n","output_type":"stream"}]}]}